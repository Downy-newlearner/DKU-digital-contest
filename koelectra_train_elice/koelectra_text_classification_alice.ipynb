{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# KoELECTRA를 활용한 AI vs Human 텍스트 분류 모델 (앨리스랩 환경)\n",
        "\n",
        "이 노트북은 한국어 ELECTRA 모델을 사용하여 AI가 생성한 텍스트와 사람이 작성한 텍스트를 분류하는 모델을 구현합니다.\n",
        "\n",
        "## 주요 특징\n",
        "- **모델**: monologg/koelectra-base-v3-discriminator\n",
        "- **평가 지표**: ROC-AUC\n",
        "- **기법**: Early Stopping, Power Tuning\n",
        "- **프레임워크**: HuggingFace Transformers\n",
        "- **환경**: 앨리스랩 클라우드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import datetime\n",
        "import warnings\n",
        "\n",
        "# 경고 메시지 필터링\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✅ 라이브러리 로드 완료\")\n",
        "print(f\"PyTorch 버전: {torch.__version__}\")\n",
        "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU 개수: {torch.cuda.device_count()}\")\n",
        "    print(f\"현재 GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 파일 경로 설정 (로컬 경로)\n",
        "DATA_DIR = \"./\"\n",
        "TRAIN_FILE = \"train.csv\"\n",
        "TEST_FILE = \"test.csv\"\n",
        "SUBMISSION_FILE = \"sample_submission.csv\"\n",
        "\n",
        "# 전체 경로 생성\n",
        "train_file_path = os.path.join(DATA_DIR, TRAIN_FILE)\n",
        "test_file_path = os.path.join(DATA_DIR, TEST_FILE)\n",
        "submission_file_path = os.path.join(DATA_DIR, SUBMISSION_FILE)\n",
        "\n",
        "print(f\"훈련 데이터 경로: {train_file_path}\")\n",
        "print(f\"테스트 데이터 경로: {test_file_path}\")\n",
        "print(f\"샘플 제출 파일 경로: {submission_file_path}\")\n",
        "\n",
        "# 파일 존재 여부 확인\n",
        "required_files = [train_file_path, test_file_path, submission_file_path]\n",
        "for file_path in required_files:\n",
        "    if not os.path.isfile(file_path):\n",
        "        raise FileNotFoundError(f\"❌ 파일을 찾을 수 없습니다: {file_path}\")\n",
        "\n",
        "print(\"✅ 모든 데이터 파일 확인 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 로드\n",
        "print(\"📊 데이터 로딩 중...\")\n",
        "train_data = pd.read_csv(train_file_path, encoding='utf-8')\n",
        "test_data = pd.read_csv(test_file_path, encoding='utf-8')\n",
        "submission_data = pd.read_csv(submission_file_path, encoding='utf-8')\n",
        "\n",
        "# 데이터 정보 출력\n",
        "print(\"📊 데이터셋 정보:\")\n",
        "print(f\"Train 데이터: {train_data.shape}\")\n",
        "print(f\"Test 데이터: {test_data.shape}\")\n",
        "print(f\"Submission 데이터: {submission_data.shape}\")\n",
        "\n",
        "print(\"\\n📝 Train 데이터 컬럼:\", list(train_data.columns))\n",
        "print(\"📝 Test 데이터 컬럼:\", list(test_data.columns))\n",
        "\n",
        "print(\"\\n🎯 타겟 분포:\")\n",
        "print(train_data['generated'].value_counts())\n",
        "print(f\"\\n클래스 비율 (Human:AI) = {train_data['generated'].value_counts()[0]}:{train_data['generated'].value_counts()[1]}\")\n",
        "\n",
        "# 데이터 기본 정보\n",
        "print(\"\\n📋 데이터 기본 정보:\")\n",
        "print(f\"훈련 데이터 결측값: {train_data.isnull().sum().sum()}\")\n",
        "print(f\"테스트 데이터 결측값: {test_data.isnull().sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 설정\n",
        "MODEL_NAME = \"monologg/koelectra-base-v3-discriminator\"\n",
        "NUM_CLASSES = 2\n",
        "MAX_SEQUENCE_LENGTH = 512\n",
        "\n",
        "print(f\"🤖 사용할 모델: {MODEL_NAME}\")\n",
        "print(f\"📏 최대 시퀀스 길이: {MAX_SEQUENCE_LENGTH}\")\n",
        "\n",
        "# 토크나이저 로드\n",
        "print(\"🔧 토크나이저 로드 중...\")\n",
        "text_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "print(\"✅ 토크나이저 로드 완료\")\n",
        "\n",
        "# 분류 모델 로드\n",
        "print(\"🔧 모델 로드 중...\")\n",
        "classification_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_CLASSES\n",
        ")\n",
        "print(\"✅ 모델 로드 완료\")\n",
        "\n",
        "# GPU 사용 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "classification_model.to(device)\n",
        "print(f\"💻 사용 디바이스: {device}\")\n",
        "\n",
        "# 모델 파라미터 수 확인\n",
        "total_params = sum(p.numel() for p in classification_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in classification_model.parameters() if p.requires_grad)\n",
        "print(f\"🔢 총 파라미터 수: {total_params:,}\")\n",
        "print(f\"🔢 학습 가능한 파라미터 수: {trainable_params:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomTextDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    텍스트 분류를 위한 커스텀 데이터셋 클래스\n",
        "    \"\"\"\n",
        "    def __init__(self, text_list, label_list=None, max_seq_len=512):\n",
        "        print(f\"📝 데이터셋 생성 중... (샘플 수: {len(text_list)})\")\n",
        "        self.text_encodings = text_tokenizer(\n",
        "            text_list,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=max_seq_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        self.target_labels = label_list\n",
        "        print(f\"✅ 토큰화 완료\")\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # 인코딩된 텍스트 데이터 추출\n",
        "        data_item = {\n",
        "            key: tensor[index] for key, tensor in self.text_encodings.items()\n",
        "        }\n",
        "\n",
        "        # 라벨이 있는 경우 추가\n",
        "        if self.target_labels is not None:\n",
        "            data_item[\"labels\"] = torch.tensor(self.target_labels[index], dtype=torch.long)\n",
        "\n",
        "        return data_item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text_encodings[\"input_ids\"])\n",
        "\n",
        "print(\"✅ 커스텀 데이터셋 클래스 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 텍스트와 라벨 추출\n",
        "print(\"📝 데이터 전처리 중...\")\n",
        "text_samples = train_data[\"full_text\"].tolist()\n",
        "label_samples = train_data[\"generated\"].tolist()\n",
        "\n",
        "print(f\"총 샘플 수: {len(text_samples)}\")\n",
        "print(f\"평균 텍스트 길이: {np.mean([len(text) for text in text_samples]):.1f}자\")\n",
        "\n",
        "# 텍스트 길이 분포 확인\n",
        "text_lengths = [len(text) for text in text_samples]\n",
        "print(f\"텍스트 길이 분포:\")\n",
        "print(f\"  - 최소: {min(text_lengths)}자\")\n",
        "print(f\"  - 평균: {np.mean(text_lengths):.1f}자\")\n",
        "print(f\"  - 최대: {max(text_lengths)}자\")\n",
        "print(f\"  - 중간값: {np.median(text_lengths):.1f}자\")\n",
        "\n",
        "# 훈련/검증 데이터 분할 (95:5 비율)\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(\n",
        "    text_samples,\n",
        "    label_samples,\n",
        "    test_size=0.05,\n",
        "    stratify=label_samples,  # 클래스 비율 유지\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\n📊 데이터 분할 결과:\")\n",
        "print(f\"훈련 데이터: {len(X_train)}개\")\n",
        "print(f\"검증 데이터: {len(X_validation)}개\")\n",
        "print(f\"훈련 데이터 클래스 분포: {np.bincount(y_train)}\")\n",
        "print(f\"검증 데이터 클래스 분포: {np.bincount(y_validation)}\")\n",
        "\n",
        "# 데이터셋 객체 생성\n",
        "print(\"\\n🔧 데이터셋 객체 생성 중...\")\n",
        "print(\"🔄 훈련 데이터셋 생성...\")\n",
        "training_dataset = CustomTextDataset(X_train, y_train, MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print(\"🔄 검증 데이터셋 생성...\")\n",
        "validation_dataset = CustomTextDataset(X_validation, y_validation, MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print(\"🔄 테스트 데이터셋 생성...\")\n",
        "test_dataset = CustomTextDataset(test_data[\"paragraph_text\"].tolist(), max_seq_len=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print(\"✅ 모든 데이터셋 생성 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 훈련 파라미터 설정\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 16  # 앨리스랩 환경에 맞게 조정\n",
        "LEARNING_RATE = 2e-5\n",
        "OUTPUT_DIR = \"./results\"\n",
        "LOG_DIR = \"./logs\"\n",
        "\n",
        "# 디렉토리 생성\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"🔧 훈련 설정:\")\n",
        "print(f\"  - 에포크: {EPOCHS}\")\n",
        "print(f\"  - 배치 크기: {BATCH_SIZE}\")\n",
        "print(f\"  - 학습률: {LEARNING_RATE}\")\n",
        "print(f\"  - 출력 디렉토리: {OUTPUT_DIR}\")\n",
        "print(f\"  - 로그 디렉토리: {LOG_DIR}\")\n",
        "\n",
        "# 예상 훈련 시간 계산\n",
        "steps_per_epoch = len(X_train) // BATCH_SIZE\n",
        "total_steps = steps_per_epoch * EPOCHS\n",
        "print(f\"  - 에포크당 스텝 수: {steps_per_epoch}\")\n",
        "print(f\"  - 총 훈련 스텝 수: {total_steps}\")\n",
        "\n",
        "# TrainingArguments 설정\n",
        "try:\n",
        "    model_training_args = TrainingArguments(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"roc-auc\",\n",
        "        greater_is_better=True,\n",
        "        logging_dir=LOG_DIR,\n",
        "        logging_steps=100,\n",
        "        save_total_limit=3,\n",
        "        report_to=\"none\",\n",
        "        seed=42,\n",
        "        fp16=torch.cuda.is_available(),  # GPU 사용 시 mixed precision\n",
        "        dataloader_num_workers=2,\n",
        "        remove_unused_columns=False,\n",
        "        warmup_steps=int(total_steps * 0.1),  # 10% 워밍업\n",
        "        weight_decay=0.01\n",
        "    )\n",
        "    print(\"✅ 최신 버전 TrainingArguments 사용\")\n",
        "except TypeError:\n",
        "    # 구버전 호환\n",
        "    model_training_args = TrainingArguments(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"roc-auc\",\n",
        "        greater_is_better=True,\n",
        "        logging_dir=LOG_DIR,\n",
        "        logging_steps=100,\n",
        "        save_total_limit=3,\n",
        "        report_to=\"none\",\n",
        "        seed=42\n",
        "    )\n",
        "    print(\"✅ 구버전 TrainingArguments 사용\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_evaluation_metrics(evaluation_predictions):\n",
        "    \"\"\"\n",
        "    모델 평가를 위한 메트릭 계산 함수\n",
        "    \"\"\"\n",
        "    logits, true_labels = evaluation_predictions\n",
        "\n",
        "    # 예측 클래스 계산\n",
        "    predicted_classes = torch.argmax(torch.tensor(logits), dim=1).numpy()\n",
        "\n",
        "    # 확률 계산 (클래스 1에 대한 확률)\n",
        "    class_probabilities = F.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()\n",
        "\n",
        "    # F1 점수 계산\n",
        "    f1_score_value = f1_score(true_labels, predicted_classes)\n",
        "\n",
        "    # 정확도 계산\n",
        "    accuracy_value = (predicted_classes == true_labels).mean()\n",
        "\n",
        "    # ROC-AUC 계산\n",
        "    roc_auc_value = roc_auc_score(true_labels, class_probabilities)\n",
        "\n",
        "    # 추가 메트릭 계산\n",
        "    from sklearn.metrics import precision_score, recall_score\n",
        "    precision_value = precision_score(true_labels, predicted_classes)\n",
        "    recall_value = recall_score(true_labels, predicted_classes)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_value,\n",
        "        \"f1\": f1_score_value,\n",
        "        \"precision\": precision_value,\n",
        "        \"recall\": recall_value,\n",
        "        \"roc-auc\": roc_auc_value\n",
        "    }\n",
        "\n",
        "print(\"✅ 평가 메트릭 함수 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trainer 객체 생성\n",
        "print(\"🔧 Trainer 설정 중...\")\n",
        "model_trainer = Trainer(\n",
        "    model=classification_model,\n",
        "    args=model_training_args,\n",
        "    train_dataset=training_dataset,\n",
        "    eval_dataset=validation_dataset,\n",
        "    compute_metrics=calculate_evaluation_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n",
        "\n",
        "print(\"✅ Trainer 설정 완료\")\n",
        "print(\"🚀 모델 훈련 시작...\")\n",
        "print(f\"예상 훈련 시간: 약 {(len(X_train) // BATCH_SIZE) * EPOCHS * 2 // 60}분\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 모델 훈련 실행\n",
        "start_time = datetime.datetime.now()\n",
        "training_results = model_trainer.train()\n",
        "end_time = datetime.datetime.now()\n",
        "\n",
        "training_duration = (end_time - start_time).total_seconds()\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"✅ 모델 훈련 완료!\")\n",
        "print(f\"📈 최종 훈련 손실: {training_results.training_loss:.4f}\")\n",
        "print(f\"⏱️ 훈련 소요 시간: {training_duration // 60:.0f}분 {training_duration % 60:.0f}초\")\n",
        "print(f\"🔄 총 훈련 스텝: {training_results.global_step}\")\n",
        "print(f\"⚡ 평균 속도: {training_results.global_step / training_duration:.2f} steps/sec\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 검증 데이터로 최종 평가\n",
        "print(\"📊 검증 데이터로 최종 평가 중...\")\n",
        "eval_results = model_trainer.evaluate()\n",
        "print(\"\\n🎯 최종 검증 결과:\")\n",
        "print(\"=\" * 40)\n",
        "for key, value in eval_results.items():\n",
        "    if key.startswith('eval_'):\n",
        "        metric_name = key.replace('eval_', '').upper()\n",
        "        print(f\"  {metric_name}: {value:.4f}\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# 테스트 데이터에 대한 예측 수행\n",
        "print(\"\\n🔮 테스트 데이터 예측 중...\")\n",
        "test_predictions = model_trainer.predict(test_dataset)\n",
        "\n",
        "# 클래스 1에 대한 확률 계산\n",
        "raw_probabilities = F.softmax(torch.tensor(test_predictions.predictions), dim=1)[:, 1].numpy()\n",
        "\n",
        "print(f\"📊 예측 완료 - {len(raw_probabilities)}개 샘플\")\n",
        "print(f\"확률 통계:\")\n",
        "print(f\"  - 최소값: {raw_probabilities.min():.4f}\")\n",
        "print(f\"  - 최대값: {raw_probabilities.max():.4f}\")\n",
        "print(f\"  - 평균값: {raw_probabilities.mean():.4f}\")\n",
        "print(f\"  - 중간값: {np.median(raw_probabilities):.4f}\")\n",
        "print(f\"  - 표준편차: {raw_probabilities.std():.4f}\")\n",
        "\n",
        "# 확률 분포 확인\n",
        "print(f\"\\n확률 분포:\")\n",
        "print(f\"  - 0.0-0.1: {((raw_probabilities >= 0.0) & (raw_probabilities < 0.1)).mean():.1%}\")\n",
        "print(f\"  - 0.1-0.3: {((raw_probabilities >= 0.1) & (raw_probabilities < 0.3)).mean():.1%}\")\n",
        "print(f\"  - 0.3-0.5: {((raw_probabilities >= 0.3) & (raw_probabilities < 0.5)).mean():.1%}\")\n",
        "print(f\"  - 0.5-0.7: {((raw_probabilities >= 0.5) & (raw_probabilities < 0.7)).mean():.1%}\")\n",
        "print(f\"  - 0.7-0.9: {((raw_probabilities >= 0.7) & (raw_probabilities < 0.9)).mean():.1%}\")\n",
        "print(f\"  - 0.9-1.0: {((raw_probabilities >= 0.9) & (raw_probabilities <= 1.0)).mean():.1%}\")\n",
        "\n",
        "# 파워 튜닝 적용\n",
        "POWER_TUNING_ALPHA = 1.1  # 파워 튜닝 계수\n",
        "tuned_probabilities = np.clip(raw_probabilities ** POWER_TUNING_ALPHA, 0, 1)\n",
        "\n",
        "print(f\"\\n⚡ 파워 튜닝 적용 (α={POWER_TUNING_ALPHA})\")\n",
        "print(f\"튜닝 후 확률 통계:\")\n",
        "print(f\"  - 최소값: {tuned_probabilities.min():.4f}\")\n",
        "print(f\"  - 최대값: {tuned_probabilities.max():.4f}\")\n",
        "print(f\"  - 평균값: {tuned_probabilities.mean():.4f}\")\n",
        "print(f\"  - 중간값: {np.median(tuned_probabilities):.4f}\")\n",
        "print(f\"  - 표준편차: {tuned_probabilities.std():.4f}\")\n",
        "\n",
        "# 제출 데이터에 예측 결과 할당\n",
        "submission_data[\"generated\"] = tuned_probabilities\n",
        "print(\"✅ 예측 결과 할당 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 제출 파일 저장\n",
        "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "auc_score = eval_results.get('eval_roc-auc', 0)\n",
        "submission_filename = f\"koelectra_submission_{current_time}_auc_{auc_score:.4f}.csv\"\n",
        "final_submission_path = os.path.join(\"./\", submission_filename)\n",
        "\n",
        "# 제출 파일 저장\n",
        "submission_data.to_csv(final_submission_path, index=False)\n",
        "\n",
        "print(\"🎉 제출 파일 저장 완료!\")\n",
        "print(f\"📁 파일 경로: {final_submission_path}\")\n",
        "print(f\"📊 제출 데이터 크기: {submission_data.shape}\")\n",
        "\n",
        "# 예측 결과 요약 출력\n",
        "print(\"\\n📈 예측 결과 요약:\")\n",
        "print(\"=\" * 30)\n",
        "print(f\"평균 확률: {tuned_probabilities.mean():.4f}\")\n",
        "print(f\"표준편차: {tuned_probabilities.std():.4f}\")\n",
        "print(f\"AI 생성 예측 비율:\")\n",
        "print(f\"  - 확률 > 0.5: {(tuned_probabilities > 0.5).mean():.1%}\")\n",
        "print(f\"  - 확률 > 0.3: {(tuned_probabilities > 0.3).mean():.1%}\")\n",
        "print(f\"  - 확률 > 0.7: {(tuned_probabilities > 0.7).mean():.1%}\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# 제출 파일 미리보기\n",
        "print(\"\\n👀 제출 파일 미리보기:\")\n",
        "print(submission_data.head(10))\n",
        "\n",
        "# 모델 저장 (선택사항)\n",
        "model_save_path = f\"./koelectra_model_{current_time}\"\n",
        "print(f\"\\n💾 모델 저장 중: {model_save_path}\")\n",
        "model_trainer.save_model(model_save_path)\n",
        "text_tokenizer.save_pretrained(model_save_path)\n",
        "print(f\"✅ 모델 저장 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 실험 결과 요약\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎯 실험 결과 요약\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 기본 정보\n",
        "print(\"📋 기본 정보:\")\n",
        "print(f\"  - 모델: {MODEL_NAME}\")\n",
        "print(f\"  - 실행 환경: 앨리스랩 클라우드\")\n",
        "print(f\"  - 실행 시간: {current_time}\")\n",
        "print(f\"  - 디바이스: {device}\")\n",
        "\n",
        "# 데이터 정보\n",
        "print(\"\\n📊 데이터 정보:\")\n",
        "print(f\"  - 훈련 데이터 크기: {len(X_train):,}\")\n",
        "print(f\"  - 검증 데이터 크기: {len(X_validation):,}\")\n",
        "print(f\"  - 테스트 데이터 크기: {len(test_data):,}\")\n",
        "print(f\"  - 클래스 분포 (Human:AI): {train_data['generated'].value_counts()[0]}:{train_data['generated'].value_counts()[1]}\")\n",
        "\n",
        "# 하이퍼파라미터\n",
        "print(\"\\n⚙️ 하이퍼파라미터:\")\n",
        "print(f\"  - 배치 크기: {BATCH_SIZE}\")\n",
        "print(f\"  - 학습률: {LEARNING_RATE}\")\n",
        "print(f\"  - 최대 시퀀스 길이: {MAX_SEQUENCE_LENGTH}\")\n",
        "print(f\"  - 에포크 수: {EPOCHS}\")\n",
        "print(f\"  - 파워 튜닝 계수: {POWER_TUNING_ALPHA}\")\n",
        "\n",
        "# 훈련 결과\n",
        "print(\"\\n🏆 훈련 결과:\")\n",
        "print(f\"  - 최종 훈련 손실: {training_results.training_loss:.4f}\")\n",
        "print(f\"  - 훈련 시간: {training_duration // 60:.0f}분 {training_duration % 60:.0f}초\")\n",
        "print(f\"  - 총 훈련 스텝: {training_results.global_step}\")\n",
        "\n",
        "# 검증 성능\n",
        "print(\"\\n📈 검증 성능:\")\n",
        "for key, value in eval_results.items():\n",
        "    if key.startswith('eval_'):\n",
        "        metric_name = key.replace('eval_', '').upper()\n",
        "        print(f\"  - {metric_name}: {value:.4f}\")\n",
        "\n",
        "# 제출 정보\n",
        "print(\"\\n📤 제출 정보:\")\n",
        "print(f\"  - 제출 파일: {submission_filename}\")\n",
        "print(f\"  - 모델 저장 위치: {model_save_path}\")\n",
        "print(f\"  - 예측 평균 확률: {tuned_probabilities.mean():.4f}\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"✅ 실험 완료!\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
