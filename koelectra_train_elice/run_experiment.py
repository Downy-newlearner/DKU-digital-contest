#!/usr/bin/env python3
"""
KoELECTRA AI vs Human í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
ì•¨ë¦¬ìŠ¤ë© í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥
"""

import os
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score
import torch.nn.functional as F
import numpy as np
import datetime
import warnings
import sys

# ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§
warnings.filterwarnings('ignore')

def print_section(title):
    """ì„¹ì…˜ ì œëª©ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print(f"\n{'='*50}")
    print(f"ğŸ¯ {title}")
    print(f"{'='*50}")

def main():
    print_section("KoELECTRA í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ ì‹¤í–‰ ì‹œì‘")
    
    # 1. í™˜ê²½ í™•ì¸
    print("âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ")
    print(f"PyTorch ë²„ì „: {torch.__version__}")
    print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"GPU ê°œìˆ˜: {torch.cuda.device_count()}")
        print(f"í˜„ì¬ GPU: {torch.cuda.get_device_name(0)}")
    
    # 2. ë°ì´í„° íŒŒì¼ í™•ì¸
    print_section("ë°ì´í„° íŒŒì¼ í™•ì¸")
    
    DATA_DIR = "./"
    TRAIN_FILE = "train.csv"
    TEST_FILE = "test.csv"
    SUBMISSION_FILE = "sample_submission.csv"
    
    train_file_path = os.path.join(DATA_DIR, TRAIN_FILE)
    test_file_path = os.path.join(DATA_DIR, TEST_FILE)
    submission_file_path = os.path.join(DATA_DIR, SUBMISSION_FILE)
    
    required_files = [train_file_path, test_file_path, submission_file_path]
    for file_path in required_files:
        if not os.path.isfile(file_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            sys.exit(1)
    
    print("âœ… ëª¨ë“  ë°ì´í„° íŒŒì¼ í™•ì¸ ì™„ë£Œ")
    
    # 3. ë°ì´í„° ë¡œë“œ
    print_section("ë°ì´í„° ë¡œë“œ")
    
    train_data = pd.read_csv(train_file_path, encoding='utf-8')
    test_data = pd.read_csv(test_file_path, encoding='utf-8')
    submission_data = pd.read_csv(submission_file_path, encoding='utf-8')
    
    print(f"Train ë°ì´í„°: {train_data.shape}")
    print(f"Test ë°ì´í„°: {test_data.shape}")
    print(f"Submission ë°ì´í„°: {submission_data.shape}")
    print(f"í´ë˜ìŠ¤ ë¶„í¬: {train_data['generated'].value_counts().to_dict()}")
    
    # 4. ëª¨ë¸ ì„¤ì •
    print_section("ëª¨ë¸ ì„¤ì •")
    
    MODEL_NAME = "monologg/koelectra-base-v3-discriminator"
    NUM_CLASSES = 2
    MAX_SEQUENCE_LENGTH = 512
    
    print(f"ëª¨ë¸: {MODEL_NAME}")
    
    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    text_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    print("âœ… í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ")
    
    # ëª¨ë¸ ë¡œë“œ
    classification_model = AutoModelForSequenceClassification.from_pretrained(
        MODEL_NAME, num_labels=NUM_CLASSES
    )
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    # GPU ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    classification_model.to(device)
    print(f"ğŸ’» ë””ë°”ì´ìŠ¤: {device}")
    
    # 5. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜
    class CustomTextDataset(torch.utils.data.Dataset):
        def __init__(self, text_list, label_list=None, max_seq_len=512):
            self.text_encodings = text_tokenizer(
                text_list,
                truncation=True,
                padding=True,
                max_length=max_seq_len,
                return_tensors="pt"
            )
            self.target_labels = label_list

        def __getitem__(self, index):
            data_item = {
                key: tensor[index] for key, tensor in self.text_encodings.items()
            }
            if self.target_labels is not None:
                data_item["labels"] = torch.tensor(self.target_labels[index], dtype=torch.long)
            return data_item

        def __len__(self):
            return len(self.text_encodings["input_ids"])
    
    # 6. ë°ì´í„° ì „ì²˜ë¦¬
    print_section("ë°ì´í„° ì „ì²˜ë¦¬")
    
    text_samples = train_data["full_text"].tolist()
    label_samples = train_data["generated"].tolist()
    
    # í›ˆë ¨/ê²€ì¦ ë¶„í• 
    X_train, X_validation, y_train, y_validation = train_test_split(
        text_samples, label_samples, test_size=0.05, stratify=label_samples, random_state=42
    )
    
    print(f"í›ˆë ¨ ë°ì´í„°: {len(X_train)}ê°œ")
    print(f"ê²€ì¦ ë°ì´í„°: {len(X_validation)}ê°œ")
    
    # ë°ì´í„°ì…‹ ìƒì„±
    training_dataset = CustomTextDataset(X_train, y_train, MAX_SEQUENCE_LENGTH)
    validation_dataset = CustomTextDataset(X_validation, y_validation, MAX_SEQUENCE_LENGTH)
    test_dataset = CustomTextDataset(test_data["paragraph_text"].tolist(), max_seq_len=MAX_SEQUENCE_LENGTH)
    
    print("âœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
    
    # 7. í›ˆë ¨ ì„¤ì •
    print_section("í›ˆë ¨ ì„¤ì •")
    
    EPOCHS = 10
    BATCH_SIZE = 16
    LEARNING_RATE = 2e-5
    OUTPUT_DIR = "./results"
    LOG_DIR = "./logs"
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    os.makedirs(LOG_DIR, exist_ok=True)
    
    print(f"ì—í¬í¬: {EPOCHS}, ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}, í•™ìŠµë¥ : {LEARNING_RATE}")
    
    # 8. í‰ê°€ ë©”íŠ¸ë¦­ í•¨ìˆ˜
    def calculate_evaluation_metrics(evaluation_predictions):
        logits, true_labels = evaluation_predictions
        predicted_classes = torch.argmax(torch.tensor(logits), dim=1).numpy()
        class_probabilities = F.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()
        
        return {
            "accuracy": (predicted_classes == true_labels).mean(),
            "f1": f1_score(true_labels, predicted_classes),
            "precision": precision_score(true_labels, predicted_classes),
            "recall": recall_score(true_labels, predicted_classes),
            "roc-auc": roc_auc_score(true_labels, class_probabilities)
        }
    
    # 9. TrainingArguments ì„¤ì •
    try:
        model_training_args = TrainingArguments(
            output_dir=OUTPUT_DIR,
            num_train_epochs=EPOCHS,
            per_device_train_batch_size=BATCH_SIZE,
            per_device_eval_batch_size=BATCH_SIZE,
            learning_rate=LEARNING_RATE,
            evaluation_strategy="epoch",
            save_strategy="epoch",
            load_best_model_at_end=True,
            metric_for_best_model="roc-auc",
            greater_is_better=True,
            logging_dir=LOG_DIR,
            logging_steps=100,
            save_total_limit=3,
            report_to="none",
            seed=42,
            fp16=torch.cuda.is_available(),
            dataloader_num_workers=2,
            remove_unused_columns=False
        )
    except TypeError:
        model_training_args = TrainingArguments(
            output_dir=OUTPUT_DIR,
            num_train_epochs=EPOCHS,
            per_device_train_batch_size=BATCH_SIZE,
            per_device_eval_batch_size=BATCH_SIZE,
            learning_rate=LEARNING_RATE,
            eval_strategy="epoch",
            save_strategy="epoch",
            load_best_model_at_end=True,
            metric_for_best_model="roc-auc",
            greater_is_better=True,
            logging_dir=LOG_DIR,
            logging_steps=100,
            save_total_limit=3,
            report_to="none",
            seed=42
        )
    
    # 10. í›ˆë ¨ ì‹¤í–‰
    print_section("ëª¨ë¸ í›ˆë ¨")
    
    model_trainer = Trainer(
        model=classification_model,
        args=model_training_args,
        train_dataset=training_dataset,
        eval_dataset=validation_dataset,
        compute_metrics=calculate_evaluation_metrics,
        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]
    )
    
    start_time = datetime.datetime.now()
    training_results = model_trainer.train()
    end_time = datetime.datetime.now()
    
    training_duration = (end_time - start_time).total_seconds()
    print(f"âœ… í›ˆë ¨ ì™„ë£Œ!")
    print(f"í›ˆë ¨ ì‹œê°„: {training_duration // 60:.0f}ë¶„ {training_duration % 60:.0f}ì´ˆ")
    
    # 11. í‰ê°€ ë° ì˜ˆì¸¡
    print_section("í‰ê°€ ë° ì˜ˆì¸¡")
    
    eval_results = model_trainer.evaluate()
    print("ê²€ì¦ ê²°ê³¼:")
    for key, value in eval_results.items():
        if key.startswith('eval_'):
            print(f"  {key}: {value:.4f}")
    
    # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
    test_predictions = model_trainer.predict(test_dataset)
    raw_probabilities = F.softmax(torch.tensor(test_predictions.predictions), dim=1)[:, 1].numpy()
    
    # íŒŒì›Œ íŠœë‹
    POWER_TUNING_ALPHA = 1.1
    tuned_probabilities = np.clip(raw_probabilities ** POWER_TUNING_ALPHA, 0, 1)
    
    # 12. ì œì¶œ íŒŒì¼ ìƒì„±
    print_section("ì œì¶œ íŒŒì¼ ìƒì„±")
    
    current_time = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    auc_score = eval_results.get('eval_roc-auc', 0)
    submission_filename = f"koelectra_submission_{current_time}_auc_{auc_score:.4f}.csv"
    
    submission_data["generated"] = tuned_probabilities
    submission_data.to_csv(submission_filename, index=False)
    
    print(f"âœ… ì œì¶œ íŒŒì¼ ì €ì¥: {submission_filename}")
    
    # 13. ëª¨ë¸ ì €ì¥
    model_save_path = f"./koelectra_model_{current_time}"
    model_trainer.save_model(model_save_path)
    text_tokenizer.save_pretrained(model_save_path)
    
    print(f"âœ… ëª¨ë¸ ì €ì¥: {model_save_path}")
    
    # 14. ê²°ê³¼ ìš”ì•½
    print_section("ì‹¤í—˜ ê²°ê³¼ ìš”ì•½")
    
    print(f"ëª¨ë¸: {MODEL_NAME}")
    print(f"í›ˆë ¨ ë°ì´í„°: {len(X_train):,}ê°œ")
    print(f"ê²€ì¦ ë°ì´í„°: {len(X_validation):,}ê°œ")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_data):,}ê°œ")
    print(f"í›ˆë ¨ ì‹œê°„: {training_duration // 60:.0f}ë¶„ {training_duration % 60:.0f}ì´ˆ")
    print(f"ìµœì¢… ROC-AUC: {auc_score:.4f}")
    print(f"ì œì¶œ íŒŒì¼: {submission_filename}")
    print(f"ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {model_save_path}")
    
    print_section("ì‹¤í—˜ ì™„ë£Œ")

if __name__ == "__main__":
    main() 